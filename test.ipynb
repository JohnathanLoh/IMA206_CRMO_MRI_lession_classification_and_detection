{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "import tensorflow as tf\n",
    "import tensorflow.python.platform\n",
    "from tensorflow.python.platform import gfile\n",
    "from skimage.io import imread\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from sklearn import svm\n",
    "from skimage import io\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import color\n",
    "from skimage.filters import try_all_threshold\n",
    "from skimage.filters import threshold_isodata\n",
    "from skimage.filters import threshold_li\n",
    "from skimage.filters import threshold_mean\n",
    "from skimage.filters import threshold_minimum\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.filters import threshold_triangle\n",
    "from skimage.filters import threshold_yen\n",
    "from skimage.filters import threshold_local\n",
    "from skimage.filters import sobel\n",
    "from skimage.filters import median\n",
    "\n",
    "from skimage.measure import label\n",
    "\n",
    "from skimage.morphology import disk\n",
    "from skimage.morphology import opening,closing,disk\n",
    "\n",
    "from skimage import util \n",
    "from skimage.color import label2rgb\n",
    "\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph():\n",
    "    with gfile.FastGFile('classify_image_graph_def.pb', 'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "    _ = tf.import_graph_def(graph_def, name='')\n",
    "\n",
    "def extract_features(image): #image is the path of image\n",
    "    create_graph() #necessary for getting tensors\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        next_to_last_tensor = sess.graph.get_tensor_by_name('pool_3:0')\n",
    "\n",
    "        image_data = gfile.FastGFile(image, 'rb').read()\n",
    "\n",
    "        predictions = sess.run(next_to_last_tensor, {'DecodeJpeg/contents:0': image_data})\n",
    "        return np.squeeze(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='../IRM palier genoux avec lésion(s)/88AJ_OCMR+.jpg' #put here the path of image you want to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-d174201f6bc4>:2: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.gfile.GFile.\n"
     ]
    }
   ],
   "source": [
    "features=extract_features(path) #put here the path of image you want to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(image):\n",
    "    result = {}\n",
    "\n",
    "    #hog = cv2.HOGDescriptor(winSize,blockSize,blockStride,cellSize,Bin)\n",
    "    hog = cv2.HOGDescriptor()\n",
    "    h,w = image.shape\n",
    "    # 64*128滑窗检测，跳数为8, 即把图像划分为多个子图，检测子图是否属于legion部分    \n",
    "    for x in range(0,h-128,4):\n",
    "        for y in range(0,w-64,8):\n",
    "            block = image[x:x+129,y:y+65]\n",
    "            #print(block.shape)\n",
    "            feature = hog.compute(block)\n",
    "            if feature is None:\n",
    "                continue\n",
    "            else:\n",
    "                feature = feature.ravel().reshape(1,3780) \n",
    "                prob_temp=model.predict_proba(feature)[0][0]\n",
    "                \n",
    "                if prob_temp > 0.99: \n",
    "                    result[(x,y)] = 1\n",
    "    return result\n",
    "\n",
    " \n",
    "#  Merging all all sub-areas containing the lesions into a larger areas having lesions\n",
    "def drawVirtrualBox2(image_ori,image_trai, res):\n",
    "    count = 0\n",
    "    for k,v in res.items():\n",
    "        if v==0:\n",
    "            continue\n",
    "        x,y = k\n",
    "        maxy, maxx, minx, miny = y + 64, x + 128, x, y\n",
    "        for k1 in res.keys():\n",
    "            x1,y1 = k1\n",
    "            if minx<=x1<=maxx and miny<=y1<=maxy or miny<=y1+64<=maxy:\n",
    "                res[k1]=0\n",
    "                maxy = max(maxy, y1+64)\n",
    "                maxx = max(maxx, x1+128)\n",
    "                miny = min(miny, y1)\n",
    "                minx = min(minx, x1)\n",
    "        count +=1\n",
    "        cv2.rectangle(image_ori, (miny,minx), (maxy,maxx), (0,0,255), 2)\n",
    "        cv2.rectangle(image_trai, (miny,minx), (maxy,maxx), (0,0, 255), 2)\n",
    "        \n",
    "    #cv2.imshow(\"result\", image)  # It cannot be used in jupyter notebook\n",
    "    cv2.imwrite('result_merged_Box_ori.jpg', image_ori)\n",
    "    cv2.imwrite('result_merged_Box_trai.jpg', image_trai)\n",
    "\n",
    "# Detect all sub-areas containing the lesions\n",
    "def drawVirtrualBox(image_ori,image_trai,res):\n",
    "    for v in res.keys():\n",
    "        x,y = v\n",
    "        cv2.rectangle(image_ori, (y,x), (y+64,x+128), (0,0,255) ,1)\n",
    "        cv2.rectangle(image_trai, (y,x), (y+64,x+128), (0,0,255) ,1)\n",
    "   \n",
    "    \n",
    "    cv2.imwrite('result_allBox_ori.jpg', image_ori)\n",
    "    cv2.imwrite('result_allBox_trai.jpg', image_trai)\n",
    "    #cv2.imshow('result',image)  # It cannot be used in jupyter notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model svm and its weights that we had trained above. \n",
    "with open('sample_svm.pickle','rb') as fr:\n",
    "    model_classification = pickle.load(fr)\n",
    "with open('training_result.pickle','rb') as fr:\n",
    "    model_frame = pickle.load(fr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here to add the annotation function of Johnathan\n",
    "\n",
    "def annotation_and_save():\n",
    "    img = io.imread(path)\n",
    "    img = color.rgb2gray(img)\n",
    "    thresh_yen = threshold_yen(img)\n",
    "    \n",
    "    # opening used to remove line artifacts\n",
    "    binary_yen = opening(img > thresh_yen,disk(5))   \n",
    "    \n",
    "    yen_red = np.zeros((img.shape[0],img.shape[1]))\n",
    "    yen_red[:,:] = binary_yen*255\n",
    "\n",
    "    contour_im = sobel(img)\n",
    "    thresh = threshold_triangle(contour_im)\n",
    "\n",
    "    outline_binary = contour_im > thresh\n",
    "    outline_binary_neg = util.invert(outline_binary)\n",
    "    \n",
    "    x,y = img.shape\n",
    "\n",
    "    overlay_rgb = np.ones((x,y,3))\n",
    "    overlay_rgb[:,:,0] = binary_yen\n",
    "    overlay_rgb[:,:,1] = outline_binary_neg\n",
    "    \n",
    "    imageio.imwrite('traitement.jpg', overlay_rgb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    }
   ],
   "source": [
    "annotation_and_save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_frame_annotation():\n",
    "    img = np.asarray(Image.open(path).convert('L'))\n",
    "    result = test(img)    \n",
    "    drawVirtrualBox(cv2.imread(path),cv2.imread(\"traitement.jpg\"),result)\n",
    "    drawVirtrualBox2(cv2.imread(path),cv2.imread(\"traitement.jpg\"),result)\n",
    "    # show the testing results\n",
    "    fig, axes = plt.subplots(ncols = 4, figsize=(16, 10))\n",
    "    ax = axes.ravel()\n",
    "    ax[0] = plt.subplot(1, 2, 1)\n",
    "    ax[1] = plt.subplot(1, 2, 2)\n",
    "    img_ori = mpimg.imread('original.jpg')\n",
    "    ax[0].imshow(img_ori,cmap=plt.cm.gray)\n",
    "    ax[0].set_title('Original Image')\n",
    "\n",
    "    result_allBox_ori = mpimg.imread('result_allBox_ori.jpg')\n",
    "    ax[1].imshow(result_allBox_ori,cmap=plt.cm.gray)\n",
    "    ax[1].set_title('All sub-areas detected  ')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "    fig, axes = plt.subplots(ncols = 6, figsize=(16, 10))\n",
    "    ax = axes.ravel()\n",
    "    ax[0] = plt.subplot(1, 2, 1)\n",
    "    ax[1] = plt.subplot(1, 2, 2)\n",
    "\n",
    "    result_trai = mpimg.imread('traitement.jpg')\n",
    "    ax[0].imshow(result_trai,cmap=plt.cm.gray)\n",
    "    ax[0].set_title('Image after post-traitment')\n",
    "\n",
    "    result_allBox_trai = mpimg.imread('result_allBox_trai.jpg')\n",
    "    ax[1].imshow(result_allBox_trai,cmap=plt.cm.gray)\n",
    "    ax[1].set_title('All sub-areas detected')\n",
    "    plt.show()\n",
    "\n",
    "    fig, axes = plt.subplots(ncols = 6, figsize=(16, 10))\n",
    "    ax = axes.ravel()\n",
    "    ax[0] = plt.subplot(1, 2, 1)\n",
    "    ax[1] = plt.subplot(1, 2, 2)\n",
    "\n",
    "    result_merged_Box_ori = mpimg.imread('result_merged_Box_ori.jpg')\n",
    "    ax[0].imshow(result_merged_Box_ori,cmap=plt.cm.gray)\n",
    "    ax[0].set_title('Area detected')\n",
    "\n",
    "    result_merged_Box_trai = mpimg.imread('result_merged_Box_trai.jpg')\n",
    "    ax[1].imshow(result_merged_Box_trai,cmap=plt.cm.gray)\n",
    "    ax[1].set_title('Area detected')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability with lesions:  0.7210514208252612\n",
      "We classify the MRI image as uncertain.\n"
     ]
    }
   ],
   "source": [
    "proba=model_classification.predict_proba(features.reshape(1,-1))[0,0]\n",
    "print('The probability with lesions: ',proba)\n",
    "if proba>0.8:\n",
    "    print('We classify the MRI image as with lesions. And we display the frame and annotation of possible lesions.')\n",
    "    print_frame_annotation()\n",
    "elif proba<0.2:\n",
    "    print('We classify the MRI image as without lesions.')\n",
    "else:\n",
    "    print('We classify the MRI image as uncertain. But we still display the frame and annotation of possible lesions.')\n",
    "    print_frame_annotation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
